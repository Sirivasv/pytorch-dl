{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/shakespeare.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose mi\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'd',\n",
       " 1: '8',\n",
       " 2: 'f',\n",
       " 3: '6',\n",
       " 4: 'S',\n",
       " 5: 'b',\n",
       " 6: ')',\n",
       " 7: ',',\n",
       " 8: 'c',\n",
       " 9: 'q',\n",
       " 10: '\"',\n",
       " 11: 'B',\n",
       " 12: ':',\n",
       " 13: 'E',\n",
       " 14: 'i',\n",
       " 15: 'O',\n",
       " 16: 'u',\n",
       " 17: 'H',\n",
       " 18: '7',\n",
       " 19: 'W',\n",
       " 20: '|',\n",
       " 21: 'F',\n",
       " 22: 'p',\n",
       " 23: '_',\n",
       " 24: 'o',\n",
       " 25: ']',\n",
       " 26: 'z',\n",
       " 27: 'Z',\n",
       " 28: 'k',\n",
       " 29: '1',\n",
       " 30: 'A',\n",
       " 31: '3',\n",
       " 32: 'L',\n",
       " 33: '5',\n",
       " 34: 'Q',\n",
       " 35: 'C',\n",
       " 36: '!',\n",
       " 37: 'j',\n",
       " 38: 'M',\n",
       " 39: 'l',\n",
       " 40: 'I',\n",
       " 41: '&',\n",
       " 42: 's',\n",
       " 43: ';',\n",
       " 44: 'v',\n",
       " 45: 'K',\n",
       " 46: 'e',\n",
       " 47: '2',\n",
       " 48: ' ',\n",
       " 49: 'T',\n",
       " 50: '9',\n",
       " 51: '<',\n",
       " 52: '-',\n",
       " 53: 'V',\n",
       " 54: '`',\n",
       " 55: 'g',\n",
       " 56: 'w',\n",
       " 57: 'a',\n",
       " 58: 'G',\n",
       " 59: '?',\n",
       " 60: 'J',\n",
       " 61: 'D',\n",
       " 62: 'h',\n",
       " 63: '4',\n",
       " 64: 'X',\n",
       " 65: 't',\n",
       " 66: '\\n',\n",
       " 67: \"'\",\n",
       " 68: '0',\n",
       " 69: 'r',\n",
       " 70: 'Y',\n",
       " 71: 'n',\n",
       " 72: 'm',\n",
       " 73: '>',\n",
       " 74: 'N',\n",
       " 75: 'R',\n",
       " 76: '.',\n",
       " 77: 'x',\n",
       " 78: '(',\n",
       " 79: 'U',\n",
       " 80: '[',\n",
       " 81: '}',\n",
       " 82: 'P',\n",
       " 83: 'y'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num --> letter\n",
    "decoder = dict(enumerate(all_characters))\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter --> num\n",
    "encoder = {char: ind for ind, char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 0,\n",
       " '8': 1,\n",
       " 'f': 2,\n",
       " '6': 3,\n",
       " 'S': 4,\n",
       " 'b': 5,\n",
       " ')': 6,\n",
       " ',': 7,\n",
       " 'c': 8,\n",
       " 'q': 9,\n",
       " '\"': 10,\n",
       " 'B': 11,\n",
       " ':': 12,\n",
       " 'E': 13,\n",
       " 'i': 14,\n",
       " 'O': 15,\n",
       " 'u': 16,\n",
       " 'H': 17,\n",
       " '7': 18,\n",
       " 'W': 19,\n",
       " '|': 20,\n",
       " 'F': 21,\n",
       " 'p': 22,\n",
       " '_': 23,\n",
       " 'o': 24,\n",
       " ']': 25,\n",
       " 'z': 26,\n",
       " 'Z': 27,\n",
       " 'k': 28,\n",
       " '1': 29,\n",
       " 'A': 30,\n",
       " '3': 31,\n",
       " 'L': 32,\n",
       " '5': 33,\n",
       " 'Q': 34,\n",
       " 'C': 35,\n",
       " '!': 36,\n",
       " 'j': 37,\n",
       " 'M': 38,\n",
       " 'l': 39,\n",
       " 'I': 40,\n",
       " '&': 41,\n",
       " 's': 42,\n",
       " ';': 43,\n",
       " 'v': 44,\n",
       " 'K': 45,\n",
       " 'e': 46,\n",
       " '2': 47,\n",
       " ' ': 48,\n",
       " 'T': 49,\n",
       " '9': 50,\n",
       " '<': 51,\n",
       " '-': 52,\n",
       " 'V': 53,\n",
       " '`': 54,\n",
       " 'g': 55,\n",
       " 'w': 56,\n",
       " 'a': 57,\n",
       " 'G': 58,\n",
       " '?': 59,\n",
       " 'J': 60,\n",
       " 'D': 61,\n",
       " 'h': 62,\n",
       " '4': 63,\n",
       " 'X': 64,\n",
       " 't': 65,\n",
       " '\\n': 66,\n",
       " \"'\": 67,\n",
       " '0': 68,\n",
       " 'r': 69,\n",
       " 'Y': 70,\n",
       " 'n': 71,\n",
       " 'm': 72,\n",
       " '>': 73,\n",
       " 'N': 74,\n",
       " 'R': 75,\n",
       " '.': 76,\n",
       " 'x': 77,\n",
       " '(': 78,\n",
       " 'U': 79,\n",
       " '[': 80,\n",
       " '}': 81,\n",
       " 'P': 82,\n",
       " 'y': 83}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 29, 66, 48, 48, 21, 69, 24, 72, 48,  2, 57, 14,\n",
       "       69, 46, 42, 65, 48,  8, 69, 46, 57, 65, 16, 69, 46, 42, 48, 56, 46,\n",
       "       48,  0, 46, 42, 14, 69, 46, 48, 14, 71,  8, 69, 46, 57, 42, 46,  7,\n",
       "       66, 48, 48, 49, 62, 57, 65, 48, 65, 62, 46, 69, 46,  5, 83, 48,  5,\n",
       "       46, 57, 16, 65, 83, 67, 42, 48, 69, 24, 42, 46, 48, 72, 14, 55, 62,\n",
       "       65, 48, 71, 46, 44, 46, 69, 48,  0, 14, 46,  7, 66, 48, 48, 11, 16,\n",
       "       65, 48, 57, 42, 48, 65, 62, 46, 48, 69, 14, 22, 46, 69, 48, 42, 62,\n",
       "       24, 16, 39,  0, 48,  5, 83, 48, 65, 14, 72, 46, 48,  0, 46,  8, 46,\n",
       "       57, 42, 46,  7, 66, 48, 48, 17, 14, 42, 48, 65, 46, 71,  0, 46, 69,\n",
       "       48, 62, 46, 14, 69, 48, 72, 14, 55, 62, 65, 48,  5, 46, 57, 69, 48,\n",
       "       62, 14, 42, 48, 72, 46, 72, 24, 69, 83, 12, 66, 48, 48, 11, 16, 65,\n",
       "       48, 65, 62, 24, 16, 48,  8, 24, 71, 65, 69, 57,  8, 65, 46,  0, 48,\n",
       "       65, 24, 48, 65, 62, 14, 71, 46, 48, 24, 56, 71, 48,  5, 69, 14, 55,\n",
       "       62, 65, 48, 46, 83, 46, 42,  7, 66, 48, 48, 21, 46, 46,  0, 67, 42,\n",
       "       65, 48, 65, 62, 83, 48, 39, 14, 55, 62, 65, 67, 42, 48,  2, 39, 57,\n",
       "       72, 46, 48, 56, 14, 65, 62, 48, 42, 46, 39,  2, 52, 42, 16,  5, 42,\n",
       "       65, 57, 71, 65, 14, 57, 39, 48,  2, 16, 46, 39,  7, 66, 48, 48, 38,\n",
       "       57, 28, 14, 71, 55, 48, 57, 48,  2, 57, 72, 14, 71, 46, 48, 56, 62,\n",
       "       46, 69, 46, 48, 57,  5, 16, 71,  0, 57, 71,  8, 46, 48, 39, 14, 46,\n",
       "       42,  7, 66, 48, 48, 49, 62, 83, 48, 42, 46, 39,  2, 48, 65, 62, 83,\n",
       "       48,  2, 24, 46,  7, 48, 65, 24, 48, 65, 62, 83, 48, 42, 56, 46, 46,\n",
       "       65, 48, 42, 46, 39,  2, 48, 65, 24, 24, 48,  8, 69, 16, 46, 39, 12,\n",
       "       66, 48, 48, 49, 62, 24, 16, 48, 65, 62, 57, 65, 48, 57, 69, 65, 48,\n",
       "       71, 24, 56, 48, 65, 62, 46, 48, 56, 24, 69, 39,  0, 67, 42, 48,  2,\n",
       "       69, 46, 42, 62, 48, 24, 69, 71, 57, 72, 46, 71, 65,  7, 66, 48, 48,\n",
       "       30, 71,  0, 48, 24, 71, 39, 83, 48, 62, 46, 69, 57, 39,  0, 48, 65,\n",
       "       24, 48, 65, 62, 46, 48, 55, 57, 16,  0, 83, 48, 42, 22, 69, 14, 71,\n",
       "       55,  7, 66, 48, 48, 19, 14, 65, 62, 14, 71, 48, 65, 62, 14, 71, 46,\n",
       "       48, 24, 56, 71, 48,  5, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    \n",
    "    # encoded_text --> batch of encoded text\n",
    "    # num_uni_chars --> len(set(text))\n",
    "    \n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    \n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()]  = 1.0\n",
    "    \n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 0])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(arr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text.reshape((5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    # X : encoded text of legth seq_len\n",
    "    # Y : encoded text shifted by one\n",
    "    \n",
    "    # how many chars per batch?\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    # how many batches can we make, given the len of the encoded text?\n",
    "    num_batches_avail = int(len(encoded_text)/char_per_batch)\n",
    "    \n",
    "    # Cut off the end of the encoded text, that won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n",
    "\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "    \n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        # zeros array to the same shape as x\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, n+seq_len]\n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:,-1] = encoded_text[:, 0]\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = encoded_text[:20]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text, samp_per_batch=2, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66, 48, 48, 48, 48],\n",
       "       [48, 48, 48, 48, 48]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 48, 48, 48, 48],\n",
       "       [48, 48, 48, 48, 48]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4, drop_prob=0.5, use_gpu=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind, char in decoder.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        \n",
    "        return final_out, hidden\n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda(), torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden), torch.zeros(self.num_layers, batch_size, self.num_hidden))\n",
    "        \n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(all_chars=all_characters,\n",
    "                  num_hidden=512,\n",
    "                  num_layers=3,\n",
    "                  drop_prob=0.5,\n",
    "                  use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5470292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_param = []\n",
    "\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))\n",
    "\n",
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4901048, 544561)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percent = 0.9\n",
    "train_ind = int(len(encoded_text)*train_percent)\n",
    "\n",
    "train_data = encoded_text[:train_ind]\n",
    "val_data = encoded_text[train_ind:]\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 100\n",
    "\n",
    "seq_len = 100\n",
    "\n",
    "tracker = 0\n",
    "num_char = max(encoded_text) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-33aed92e191b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mlstm_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorchenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "if model.use_gpu:\n",
    "    model.cuda()\n",
    "    \n",
    "for i in range(epochs):\n",
    "    \n",
    "    hidden = model.hidden_state(batch_size)\n",
    "    \n",
    "    for x,y in generate_batches(train_data, batch_size, seq_len):\n",
    "    \n",
    "        tracker += 1\n",
    "        \n",
    "        x = one_hot_encoder(x, num_char)\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        targets = torch.from_numpy(y)\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "            \n",
    "        lstm_output, hidden = model.forward(inputs, hidden)\n",
    "        loss = criterion(lstm_output, targets.view(batch_size*seq_len).long())\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if tracker % 25 == 0:\n",
    "            \n",
    "            val_hidden = model.hidden_state(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data, batch_size, seq_len):\n",
    "                \n",
    "                x = one_hot_encoder(x, num_char)\n",
    "        \n",
    "                inputs = torch.from_numpy(x)\n",
    "                targets = torch.from_numpy(y)\n",
    "\n",
    "                if model.use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                \n",
    "                val_hidden = tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output, val_hidden = model.forward(inputs, val_hidden)\n",
    "                val_loss = criterion(lstm_output, targets.view(batch_size*seq_len).long())\n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            print(f\"EPOCH: {i} step: {tracker} VAL LOSS: {val_loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hidden512_layers3_shakes_saul.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
